A **document-aware chatbot** built with **LangChain**, **Hugging Face embeddings**,  
**Pinecone vector database**, and a **2-bit quantized LLaMA model** for efficient local inference.  
The chatbot supports custom knowledge ingestion, retrieval-augmented generation, and a web UI for interaction.
---

## ğŸš€ Tech Stack

- **Python** â€“ Core language  
- **LangChain** â€“ Orchestration framework for LLMs and retrieval  
- **Hugging Face Transformers** â€“ Embedding models for vectorization  
- **Pinecone** â€“ Vector database for semantic search  
- **LLaMA (2-bit quantized)** â€“ Lightweight, efficient open-source LLM for answering queries  
- **Flask** â€“ Backend web framework for serving the chatbot  
- **Jinja2 + HTML/CSS/JS** â€“ Web interface (`templates/` + `static/`)  


---

## âœ¨ Features

- ğŸ”— **LangChain-powered conversation flow**  
- ğŸ“‘ **Document ingestion & embedding** with Hugging Face models  
- ğŸ“¦ **Pinecone integration** for scalable semantic search  
- ğŸ¦™ **Local inference with LLaMA (2-bit quantized)** for cost-efficient LLM usage  
- ğŸŒ **Flask web interface** for chatting in real time  
- âš¡ **Retrieval-Augmented Generation (RAG)** â€” combines embeddings + LLM output  
- ğŸ§ª **Research scripts** for experimenting with custom models and pipelines  

## ğŸ“‚ Project Structure

```bash
custom-chatbot/
â”œâ”€â”€ app.py              # Main Flask application
â”œâ”€â”€ requirement.txt     # Dependencies
â”œâ”€â”€ setup.py            # Install script
â”œâ”€â”€ store_index.py      # Builds & stores embeddings into Pinecone
â”œâ”€â”€ template.py         # Template utilities
â”‚
â”œâ”€â”€ data/               # Knowledge base / documents
â”œâ”€â”€ model/              # Quantized LLaMA model files
â”œâ”€â”€ research/           # Experimental notebooks & scripts
â”œâ”€â”€ src/                # Core source code (chains, utils, configs)
â”œâ”€â”€ static/             # CSS, JS, frontend assets
â””â”€â”€ templates/          # HTML templates for web interface
